{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiprocessing in Python leverages multiple processes to parallelize computation, with each process having its own memory space. \n",
    "\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/Ziaeemehr/workshop_hpcpy/blob/main/notebooks/multiprocessing/note_multiprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Check if running on Google Colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "    print(\"Running on Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"Running locally\")\n",
    "\n",
    "# Clone repository if on Colab and not already cloned\n",
    "if IN_COLAB:\n",
    "    if not os.path.exists('/content/workshop_hpcpy'):\n",
    "        print(\"Cloning workshop_hpcpy repository...\")\n",
    "        os.system('git clone https://github.com/Ziaeemehr/workshop_hpcpy.git /content/workshop_hpcpy')\n",
    "    \n",
    "    # Change to notebook directory\n",
    "    os.chdir('/content/workshop_hpcpy/notebooks/multiprocessing')\n",
    "    print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: ForkPoolWorker-48, num: 3, square: 9 \n",
      "ID: ForkPoolWorker-47, num: 0, square: 0 \n",
      "ID: ForkPoolWorker-50, num: 1, square: 1 \n",
      "ID: ForkPoolWorker-49, num: 2, square: 4 \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "import multiprocessing as mp\n",
    "\n",
    "def square(num):\n",
    "    # print the process ID\n",
    "    print(f'ID: {mp.current_process().name}, num: {num}, square: {num * num} \\n')\n",
    "    sleep(1)\n",
    "\n",
    "with mp.Pool(processes=4) as p:\n",
    "    p.map(square, range(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing output in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "def square(num):\n",
    "    return num * num\n",
    "\n",
    "with mp.Pool(processes=4) as p:\n",
    "    result =  p.map(square, range(10))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Pool.apply_async()` allows you to execute a function asynchronously in a separate process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 2, 4, 5, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "def task(n, m):\n",
    "    return n * n + m\n",
    "\n",
    "n = 4\n",
    "with Pool(processes=4) as p:\n",
    "    async_results = [\n",
    "        p.apply_async(task, args=(i, j)) for i in range(n) for j in range(n // 2)\n",
    "    ]\n",
    "    results = [r.get() for r in async_results]\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n",
      "0 1 1\n",
      "1 0 1\n",
      "1 1 2\n",
      "2 0 4\n",
      "2 1 5\n",
      "3 0 9\n",
      "3 1 10\n"
     ]
    }
   ],
   "source": [
    "# Sequential version\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(n // 2):\n",
    "        print(i, j, i * i + j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 205100.44it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "n = 20\n",
    "\n",
    "with mp.Pool(processes=4) as pool:\n",
    "    results = []\n",
    "    for result in tqdm.tqdm(pool.map(square, range(n)), total=n):\n",
    "        results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 10/10 [00:03<00:00,  3.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# Using apply_async with callback to update progress bar\n",
    "import numpy as np\n",
    "\n",
    "def unequal_task(n):\n",
    "    sleep(np.random.randint(1, 4))\n",
    "    return n * n\n",
    "\n",
    "n = 10\n",
    "with mp.Pool(processes=10) as pool:\n",
    "    with tqdm.tqdm(total=n, desc=\"Processing\") as pbar:\n",
    "        async_res = [\n",
    "            pool.apply_async(\n",
    "                unequal_task, \n",
    "                args=(i,), \n",
    "                callback=lambda _: pbar.update(1))\n",
    "            for i in range(n)\n",
    "        ]\n",
    "        results = [res.get() for res in async_res]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sharing data among processes\n",
    "\n",
    "If you want to share data between processes, Python's multiprocessing module provides mechanisms like Value and Array for shared memory.\n",
    "\n",
    "Example below shows how multiple processes can safely update a shared counter using a Lock to avoid race conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Process-73 withdrew $10. Remaining: $90\n",
      "\n",
      "Process Process-73 withdrew $10. Remaining: $80\n",
      "Process Process-73 withdrew $10. Remaining: $70\n",
      "Process Process-73 withdrew $10. Remaining: $60\n",
      "Process Process-73 withdrew $10. Remaining: $50\n",
      "Process Process-74 withdrew $10. Remaining: $40\n",
      "Process Process-74 withdrew $10. Remaining: $30\n",
      "Process Process-74 withdrew $10. Remaining: $20\n",
      "Process Process-74 withdrew $10. Remaining: $10\n",
      "Process Process-73 withdrew $10. Remaining: $80\n",
      "Process Process-73 withdrew $10. Remaining: $70\n",
      "Process Process-73 withdrew $10. Remaining: $60\n",
      "Process Process-73 withdrew $10. Remaining: $50\n",
      "Process Process-74 withdrew $10. Remaining: $40\n",
      "Process Process-74 withdrew $10. Remaining: $30\n",
      "Process Process-74 withdrew $10. Remaining: $20\n",
      "Process Process-74 withdrew $10. Remaining: $10\n",
      "Process Process-74 withdrew $10. Remaining: $0\n",
      "Process Process-75 couldn't withdraw (insufficient funds)\n",
      "Process Process-75 couldn't withdraw (insufficient funds)\n",
      "Process Process-75 couldn't withdraw (insufficient funds)\n",
      "Process Process-75 couldn't withdraw (insufficient funds)\n",
      "Process Process-75 couldn't withdraw (insufficient funds)\n",
      "\n",
      "Final balance: $0\n",
      "Process Process-74 withdrew $10. Remaining: $0\n",
      "Process Process-75 couldn't withdraw (insufficient funds)\n",
      "Process Process-75 couldn't withdraw (insufficient funds)\n",
      "Process Process-75 couldn't withdraw (insufficient funds)\n",
      "Process Process-75 couldn't withdraw (insufficient funds)\n",
      "Process Process-75 couldn't withdraw (insufficient funds)\n",
      "\n",
      "Final balance: $0\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Value, Lock\n",
    "\n",
    "# Each of the 3 processes attempts to withdraw money 5 times\n",
    "# There are 3 processes created\n",
    "\n",
    "def withdraw_money(balance, lock, amount):\n",
    "    \"\"\"Simulate multiple people withdrawing from a shared bank account\"\"\"\n",
    "    for _ in range(5):\n",
    "        with lock:\n",
    "            if balance.value >= amount:\n",
    "                balance.value -= amount\n",
    "                print(f\"Process {mp.current_process().name} withdrew ${amount}. Remaining: ${balance.value}\")\n",
    "            else:\n",
    "                print(f\"Process {mp.current_process().name} couldn't withdraw (insufficient funds)\")\n",
    "\n",
    "\n",
    "# Shared bank account balance\n",
    "balance = Value('i', 100)  # Start with $100, shared integer\n",
    "lock = Lock()  # Prevent race conditions\n",
    "\n",
    "processes = [mp.Process(target=withdraw_money, args=(balance, lock, 10)) for _ in range(3)]\n",
    "for p in processes:\n",
    "    p.start()\n",
    "for p in processes:\n",
    "    p.join()\n",
    "\n",
    "print(f\"\\nFinal balance: ${balance.value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sharing a List using `Manager`\n",
    "Here’s how you can use a Manager to share a list among multiple processes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Process-77 completed task 0\n",
      "Process Process-78 completed task 1\n",
      "Process Process-79 completed task 2\n",
      "Process Process-80 completed task 3\n",
      "\n",
      "Process Process-78 completed task 1\n",
      "Process Process-79 completed task 2\n",
      "Process Process-80 completed task 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completed tasks: [0, 1, 2, 3]\n",
      "Results: {'doc_0': 'Document_0_processed', 'doc_1': 'Document_1_processed', 'doc_2': 'Document_2_processed', 'doc_3': 'Document_3_processed'}\n"
     ]
    }
   ],
   "source": [
    "def process_document(task_id, completed_tasks, results_dict):\n",
    "    \"\"\"Simulate processing different documents and storing results\"\"\"\n",
    "    result = f\"Document_{task_id}_processed\"\n",
    "    completed_tasks.append(task_id)  # Add task ID to shared list\n",
    "    results_dict[f\"doc_{task_id}\"] = result  # Store result in shared dictionary\n",
    "    print(f\"Process {mp.current_process().name} completed task {task_id}\")\n",
    "\n",
    "\n",
    "# Manager() creates a server process that manages shared data structures\n",
    "# It allows multiple processes to safely access and modify the same objects\n",
    "with mp.Manager() as manager:\n",
    "    # Shared list: All processes can append task IDs here\n",
    "    # Acts like a regular Python list, but works across processes\n",
    "    completed_tasks = manager.list()\n",
    "    \n",
    "    # Shared dictionary: All processes can store key-value pairs here\n",
    "    # Acts like a regular Python dict, but works across processes\n",
    "    results_dict = manager.dict()\n",
    "    \n",
    "    # Create 4 processes, each will process one document\n",
    "    processes = [\n",
    "        mp.Process(target=process_document, args=(i, completed_tasks, results_dict)) \n",
    "        for i in range(4)\n",
    "    ]\n",
    "    \n",
    "    # Start all 4 processes (they run in parallel)\n",
    "    for p in processes:\n",
    "        p.start()\n",
    "    \n",
    "    # Wait for all processes to complete before continuing\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "    \n",
    "    # Print final results after all processes are done\n",
    "    print(f\"\\nCompleted tasks: {list(completed_tasks)}\")\n",
    "    print(f\"Results: {dict(results_dict)}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
