{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cupy\n",
    "\n",
    "CuPy is a GPU array backend that implements a subset of NumPy interface. In the following code, `cp` is an abbreviation of `cupy`, following the standard convention of abbreviating `numpy` as `np`:\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/Ziaeemehr/workshop_hpcpy/blob/main/notebooks/cupy/note.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Check if running on Google Colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "    print(\"Running on Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"Running locally\")\n",
    "\n",
    "# Clone repository if on Colab and not already cloned\n",
    "if IN_COLAB:\n",
    "    if not os.path.exists('/content/workshop_hpcpy'):\n",
    "        print(\"Cloning workshop_hpcpy repository...\")\n",
    "        os.system('git clone https://github.com/Ziaeemehr/workshop_hpcpy.git /content/workshop_hpcpy')\n",
    "    \n",
    "    # Change to notebook directory\n",
    "    os.chdir('/content/workshop_hpcpy/notebooks/cupy')\n",
    "    print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CuPy version: 13.3.0\n",
      "CUDA available: 1 GPU device(s) found\n",
      "GPU 0: NVIDIA RTX A5000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Check if CuPy is available\n",
    "try:\n",
    "    import cupy as cp\n",
    "    print(f\"CuPy version: {cp.__version__}\")\n",
    "    \n",
    "    # Check if CUDA/GPU is available\n",
    "    try:\n",
    "        device_count = cp.cuda.runtime.getDeviceCount()\n",
    "        if device_count > 0:\n",
    "            print(f\"CUDA available: {device_count} GPU device(s) found\")\n",
    "            # Print GPU info\n",
    "            for i in range(device_count):\n",
    "                props = cp.cuda.runtime.getDeviceProperties(i)\n",
    "                print(f\"GPU {i}: {props['name'].decode('utf-8')}\")\n",
    "        else:\n",
    "            print(\"CUDA available but no GPU devices found\")\n",
    "    except Exception as e:\n",
    "        print(f\"CUDA not available: {e}\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"CuPy not available. Install with: pip install cupy-cuda12x (or cupy-cuda11x)\")\n",
    "    cp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(x_cpu)=<class 'numpy.ndarray'>\n",
      "type(x_gpu.get())=<class 'numpy.ndarray'>\n",
      "type(x_gpu)=<class 'cupy.ndarray'>\n",
      "x_gpu.dtype=dtype('int64')\n"
     ]
    }
   ],
   "source": [
    "x_cpu = np.array([1, 2, 3])\n",
    "x_gpu = cp.array([1, 2, 3])\n",
    "\n",
    "\n",
    "l2_cpu = np.linalg.norm(x_cpu)\n",
    "l2_gpu = cp.linalg.norm(x_gpu)\n",
    "\n",
    "print(f\"{type(x_cpu)=}\")\n",
    "print(f\"{type(x_gpu.get())=}\")\n",
    "print(f\"{type(x_gpu)=}\") \n",
    "print(f\"{x_gpu.dtype=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tohost(x):\n",
    "    '''\n",
    "    move data to cpu\n",
    "    '''\n",
    "    return cp.asnumpy(x)\n",
    "\n",
    "\n",
    "def todevice(x):\n",
    "    '''\n",
    "    move data to gpu\n",
    "    '''\n",
    "    return cp.asarray(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "\n",
    "def run_neural_simulation(use_gpu=True, nn=68, ns=10_000, nt=20_000, dt=0.01, seed=2, dtype=np.float32):\n",
    "    \"\"\"\n",
    "    Run neural simulation on CPU or GPU\n",
    "    \n",
    "    Parameters:\n",
    "    use_gpu (bool): Whether to use GPU (CuPy) or CPU (NumPy)\n",
    "    nn (int): Number of neurons\n",
    "    ns (int): Number of samples\n",
    "    nt (int): Number of time steps\n",
    "    dt (float): Time step size\n",
    "    seed (int): Random seed\n",
    "    dtype (numpy.dtype): Data type for arrays (np.float32 for single precision, np.float64 for double precision)\n",
    "    \n",
    "    Returns:\n",
    "    list: List of x states at every 1000th time step\n",
    "    \"\"\"\n",
    "    if use_gpu:\n",
    "        xp = cp\n",
    "        print(f\"Running simulation on GPU with {dtype.__name__}\")\n",
    "    else:\n",
    "        xp = np\n",
    "        print(f\"Running simulation on CPU with {dtype.__name__}\")\n",
    "    \n",
    "    # Set seeds\n",
    "    np.random.seed(seed)\n",
    "    if use_gpu:\n",
    "        cp.random.seed(seed)\n",
    "    \n",
    "    # Initialize parameters\n",
    "    SC = xp.random.randn(nn, nn).astype(dtype)\n",
    "    x = xp.random.randn(nn, ns).astype(dtype)\n",
    "    y = xp.random.randn(nn, ns).astype(dtype)\n",
    "    eta = xp.random.randn(nn, ns).astype(dtype) + 1.01\n",
    "    tau = 3.0\n",
    "    rtau = 1 / tau\n",
    "    \n",
    "    xs = []\n",
    "    \n",
    "    for t in tqdm.trange(nt):\n",
    "        gx = SC @ x  # (nn x nn) (nn x ns) = (nn x ns)\n",
    "        dx = tau * (x - x**3 / 3 + y)\n",
    "        dy = rtau * (eta - x + 1e-2 * gx)\n",
    "        x += dt * dx\n",
    "        y += dt * dy\n",
    "        if t % 1000 == 0:\n",
    "            # Convert to numpy for storage if on GPU\n",
    "            xs.append(x.get() if use_gpu else x.copy())\n",
    "    \n",
    "    return xs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running simulation on GPU with float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:08<00:00, 2241.42it/s]\n",
      "100%|██████████| 20000/20000 [00:08<00:00, 2241.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "xs_gpu = run_neural_simulation(use_gpu=True, ns=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_cpu = run_neural_simulation(use_gpu=False, ns=10_000) # about 5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
