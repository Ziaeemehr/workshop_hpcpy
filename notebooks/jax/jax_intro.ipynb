{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a91a759c",
   "metadata": {},
   "source": [
    "# Introduction to [JAX](https://github.com/google/jax)\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/Ziaeemehr/workshop_hpcpy/blob/main/notebooks/jax/jax_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e0ee689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jax[cuda12]\n",
      "  Downloading jax-0.4.37-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting jaxlib<=0.4.37,>=0.4.36 (from jax[cuda12])\n",
      "  Downloading jaxlib-0.4.36-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting ml_dtypes>=0.4.0 (from jax[cuda12])\n",
      "  Downloading ml_dtypes-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Requirement already satisfied: numpy>=1.24 in /home/ziaee/anaconda3/envs/hpc/lib/python3.10/site-packages (from jax[cuda12]) (1.26.4)\n",
      "Collecting opt_einsum (from jax[cuda12])\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: scipy>=1.10 in /home/ziaee/anaconda3/envs/hpc/lib/python3.10/site-packages (from jax[cuda12]) (1.14.1)\n",
      "Collecting jax-cuda12-plugin<=0.4.37,>=0.4.36 (from jax-cuda12-plugin[with_cuda]<=0.4.37,>=0.4.36; extra == \"cuda12\"->jax[cuda12])\n",
      "  Downloading jax_cuda12_plugin-0.4.36-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
      "Collecting jax-cuda12-pjrt==0.4.36 (from jax-cuda12-plugin<=0.4.37,>=0.4.36->jax-cuda12-plugin[with_cuda]<=0.4.37,>=0.4.36; extra == \"cuda12\"->jax[cuda12])\n",
      "  Downloading jax_cuda12_pjrt-0.4.36-py3-none-manylinux2014_x86_64.whl.metadata (349 bytes)\n",
      "Collecting nvidia-cublas-cu12>=12.1.3.1 (from jax-cuda12-plugin[with_cuda]<=0.4.37,>=0.4.36; extra == \"cuda12\"->jax[cuda12])\n",
      "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12>=12.1.105 (from jax-cuda12-plugin[with_cuda]<=0.4.37,>=0.4.36; extra == \"cuda12\"->jax[cuda12])\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cuda-nvcc-cu12>=12.6.85 (from jax-cuda12-plugin[with_cuda]<=0.4.37,>=0.4.36; extra == \"cuda12\"->jax[cuda12])\n",
      "  Downloading nvidia_cuda_nvcc_cu12-12.6.85-py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12>=12.1.105 (from jax-cuda12-plugin[with_cuda]<=0.4.37,>=0.4.36; extra == \"cuda12\"->jax[cuda12])\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cudnn-cu12<10.0,>=9.1 (from jax-cuda12-plugin[with_cuda]<=0.4.37,>=0.4.36; extra == \"cuda12\"->jax[cuda12])\n",
      "  Downloading nvidia_cudnn_cu12-9.6.0.74-py3-none-manylinux_2_27_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cufft-cu12>=11.0.2.54 (from jax-cuda12-plugin[with_cuda]<=0.4.37,>=0.4.36; extra == \"cuda12\"->jax[cuda12])\n",
      "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12>=11.4.5.107 (from jax-cuda12-plugin[with_cuda]<=0.4.37,>=0.4.36; extra == \"cuda12\"->jax[cuda12])\n",
      "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12>=12.1.0.106 (from jax-cuda12-plugin[with_cuda]<=0.4.37,>=0.4.36; extra == \"cuda12\"->jax[cuda12])\n",
      "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12>=2.18.1 (from jax-cuda12-plugin[with_cuda]<=0.4.37,>=0.4.36; extra == \"cuda12\"->jax[cuda12])\n",
      "  Using cached nvidia_nccl_cu12-2.23.4-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12>=12.1.105 (from jax-cuda12-plugin[with_cuda]<=0.4.37,>=0.4.36; extra == \"cuda12\"->jax[cuda12])\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Downloading jaxlib-0.4.36-cp310-cp310-manylinux2014_x86_64.whl (100.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.3/100.3 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jax_cuda12_plugin-0.4.36-cp310-cp310-manylinux2014_x86_64.whl (16.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.2/16.2 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jax_cuda12_pjrt-0.4.36-py3-none-manylinux2014_x86_64.whl (101.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jax-0.4.37-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvcc_cu12-12.6.85-py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (21.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.2/21.2 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.6.0.74-py3-none-manylinux_2_27_x86_64.whl (508.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.1/508.1 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hUsing cached nvidia_nccl_cu12-2.23.4-py3-none-manylinux2014_x86_64.whl (199.0 MB)\n",
      "Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: jax-cuda12-pjrt, opt_einsum, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvcc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ml_dtypes, jax-cuda12-plugin, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, jaxlib, nvidia-cusolver-cu12, jax\n",
      "Successfully installed jax-0.4.37 jax-cuda12-pjrt-0.4.36 jax-cuda12-plugin-0.4.36 jaxlib-0.4.36 ml_dtypes-0.5.0 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvcc-cu12-12.6.85 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.6.0.74 nvidia-cufft-cu12-11.3.0.4 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-nccl-cu12-2.23.4 nvidia-nvjitlink-cu12-12.6.85 opt_einsum-3.4.0\n"
     ]
    }
   ],
   "source": [
    "# local setup\n",
    "# !pip install -U jax  # cpu-only\n",
    "!pip install -U \"jax[cuda12]\" # GPU, cuda 12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98b942e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "from timeit import default_timer\n",
    "\n",
    "@contextmanager\n",
    "def cpu_timer():\n",
    "    start = default_timer()\n",
    "    yield\n",
    "    end = default_timer()\n",
    "    print(f'Elapsed time: {(end - start) * 1000} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4fa1cb",
   "metadata": {},
   "source": [
    "## NumPy functionality with JAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae3e5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['JAX_ENABLE_X64']='True'\n",
    "\n",
    "#os.environ['XLA_PYTHON_CLIENT_PREALLOCATE']='false'\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b74fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jnp.arange(10)\n",
    "y = jnp.arange(10, 20)\n",
    "z = x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07acf5d8",
   "metadata": {},
   "source": [
    "#### Euclidean distance matrix\n",
    "\n",
    "$\n",
    "    d_e(\\mathbf x, \\mathbf y) =\n",
    "    \\begin{bmatrix}\n",
    "    \\sum_{i=1}^n (x_{1i}-y_{1i})^2 & \\sum_{i=1}^n(x_{1i}-y_{2i})^2 & \\cdots & \\sum_{i=1}^n (x_{1i}-y_{ni})^2 \\\\  \n",
    "    \\sum_{i=1}^n(x_{2i}-y_{1i})^2 & \\sum_{i=1}^n(x_{2i}-y_{2i})^2 & \\cdots & \\sum_{i=1}^n(x_{2i}-y_{ni})^2 \\\\  \n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    \\sum_{i=1}^n(x_{ni}-y_{1i})^2 & \\sum_{i=1}^n(x_{ni}-y_{2i})^2 & \\cdots & \\sum_{i=1}^n(x_{ni}-y_{ni})^2 \\\\  \n",
    "    \\end{bmatrix}\n",
    "$\n",
    "\n",
    "#### Vectorization friendly summation \n",
    "$ \n",
    "\\sum_{k=1}^n \\left(x_{ik}-y_{jk}\\right)^2 = \\left(\\vec{x_i} - \\vec {y_j}\\right)\\cdot \\left(\\vec{x_i} - \\vec{y_j}\\right)=\\vec{x_i} \\cdot \\vec{x_i} + \\vec{y_j} \\cdot \\vec{y_j} -2\\vec{x_i}\\cdot \\vec{y_j}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f941dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance_cpu(x, y):\n",
    "    x2 = np.einsum('ij,ij->i', x, x)[:, np.newaxis]\n",
    "    y2 = np.einsum('ij,ij->i', y, y)[np.newaxis, :]\n",
    "    xy = x @ y.T\n",
    "    return np.abs(x2 + y2 - 2.0 * xy)\n",
    "\n",
    "def euclidean_distance_jax(x, y):\n",
    "    x2 = jnp.einsum('ij,ij->i', x, x)[:, jnp.newaxis]\n",
    "    y2 = jnp.einsum('ij,ij->i', y, y)[jnp.newaxis, :]\n",
    "    xy = x @ y.T\n",
    "    return jnp.abs(x2 + y2 - 2.0 * xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f057d56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_rng = np.random.default_rng()\n",
    "x_cpu = np_rng.random((5000, 4000))\n",
    "y_cpu = np_rng.random((5000, 4000))\n",
    "x_gpu = jax.device_put(x_cpu).block_until_ready()\n",
    "y_gpu = jax.device_put(y_cpu).block_until_ready()\n",
    "\n",
    "with cpu_timer():\n",
    "    eu_cpu = euclidean_distance_cpu(x_cpu, y_cpu)\n",
    "\n",
    "with cpu_timer():\n",
    "    eu_jax = euclidean_distance_jax(x_gpu, y_gpu).block_until_ready()\n",
    "    \n",
    "    \n",
    "assert np.allclose(eu_cpu, jax.device_get(eu_jax))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1079c7",
   "metadata": {},
   "source": [
    "### Immutability of JAX arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c67483d",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = jnp.array([1., 2., 3., 4.])\n",
    "B = jnp.array([2., 3., 4., 5.])\n",
    "\n",
    "# This is not allowed\n",
    "#A[2] = 10.0\n",
    "\n",
    "A.at[2].set(10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b91aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb8c560",
   "metadata": {},
   "source": [
    "### Random number generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4e0202",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "x = jax.random.uniform(key, (2, 2))\n",
    "y = jax.random.uniform(key,(2, 2))\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cc3453",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "key, subkey = jax.random.split(key)\n",
    "\n",
    "x = jax.random.uniform(key, (2, 2))\n",
    "y = jax.random.uniform(subkey, (2, 2))\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f867954",
   "metadata": {},
   "source": [
    "### Scaled Exponential Linear Unit (SELU) [Klambauer et al., 2017](https://arxiv.org/abs/1706.02515)\n",
    "\n",
    "\n",
    "$$\n",
    "f(x) =  \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      \\lambda x & if & x \\gt 0 \\\\\n",
    "      \\lambda \\alpha (e^x - 1) & if & x \\le 0 \n",
    "\\end{array} \\right.\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "    \\alpha \\simeq 1.67326 \\\\\n",
    "    \\lambda \\simeq 1.050701\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e139f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from math import erfc, sqrt, exp, pi, e\n",
    "x_cpu = np.linspace(-10.0, 10.0, 10_000_000)\n",
    "\n",
    "\n",
    "alpha =  - sqrt(2.0 / pi) / (erfc(1 / sqrt(2)) * exp(1/2) - 1)\n",
    "scale = (\n",
    "    (1 - erfc(1 / sqrt(2)) * sqrt(e)) * sqrt(2 * pi) / \n",
    "    sqrt(2 * erfc(sqrt(2)) * e ** 2 + pi * e * erfc(1/sqrt(2)) ** 2 \n",
    "         - 2 * (2 + pi)* erfc(1 / sqrt(2))*sqrt(e) + pi + 2)\n",
    ")\n",
    "\n",
    "def selu_cpu(x, a=alpha, l=scale):\n",
    "    return np.where(x > 0, l * x, l * (a * np.exp(x) - a))\n",
    "\n",
    "print('SELU Cpu: ', end='')\n",
    "with cpu_timer():\n",
    "    s_cpu = selu_cpu(x_cpu)\n",
    "    \n",
    "# Similar Functionality with cupy\n",
    "'''\n",
    "import cupy as cp\n",
    "#x_gpu = cp.array(x_cpu)\n",
    "selu_kernel = cp.ElementwiseKernel(\n",
    "    'float64 X, float64 a, float64 l',\n",
    "    'float64 selu',\n",
    "    f'selu = X > 0 ? l * X : l * (a * exp(X) - a);', \n",
    "    'selu_kernel')\n",
    "    \n",
    "@cp.fuse\n",
    "def selu_fused(x, a=alpha, l=scale):\n",
    "    return cp.where(x > 0, l * x, l * (a * cp.exp(x) - a))\n",
    "\n",
    "print('SELU Cpu: ', end='')\n",
    "with cpu_timer():\n",
    "    s_cpu = selu_cpu(x_cpu)\n",
    "    \n",
    "print('SELU Fused: ', end='')\n",
    "with cupy_timer():\n",
    "    s_gpu_fused = selu_fused(x_gpu)\n",
    "    \n",
    "print('SELU Kernel: ', end='')\n",
    "with cupy_timer():\n",
    "    s_gpu_kernel = selu_kernel(x_gpu, alpha, scale)\n",
    "    \n",
    "assert(np.allclose(s_cpu, s_gpu_fused.get()))\n",
    "'''\n",
    "\n",
    "plt.close('all')\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(x_cpu, s_cpu, '--');\n",
    "ax.set_title('SELU function', )\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y(x)')\n",
    "ax.grid('Both');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33374976",
   "metadata": {},
   "source": [
    "### (Exercise) Do the same with JAX and measure the performance"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
